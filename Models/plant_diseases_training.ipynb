{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-01T04:07:07.220545Z",
     "iopub.status.busy": "2021-04-01T04:07:07.219113Z",
     "iopub.status.idle": "2021-04-01T04:07:08.449418Z",
     "shell.execute_reply": "2021-04-01T04:07:08.449952Z"
    },
    "id": "fallen-american",
    "outputId": "57265aa9-0513-4a84-de08-141b08975927",
    "papermill": {
     "duration": 1.249086,
     "end_time": "2021-04-01T04:07:08.450201",
     "exception": false,
     "start_time": "2021-04-01T04:07:07.201115",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jun 19 16:04:12 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 425.45       Driver Version: 425.45       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce MX110      WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   42C    P8    N/A /  N/A |     37MiB /  2048MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "original-somewhere",
    "papermill": {
     "duration": 0.013273,
     "end_time": "2021-04-01T04:07:08.478164",
     "exception": false,
     "start_time": "2021-04-01T04:07:08.464891",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Identify Plant Diseases\n",
    "\n",
    "We use the PlantVillage dataset [1] by Hughes et al. consists of about 87,000 healthy and unhealthy leaf images divided into 38 categories by species and disease. Here we provide a subset of our experiments on working with this data. We also end up transfer learning from MobileNet and use the weights from pre-training on ImageNet.\n",
    "\n",
    "* ![PlantVillage Dataset Samples](https://i.imgur.com/Zcxdrlc.png)\n",
    "Figure 1. PlantVillage Dataset Samples\n",
    "\n",
    "## Classes\n",
    "\n",
    "The following 38 classes are availaible in the dataset\n",
    "\n",
    "- `Apple___Apple_scab` \n",
    "- `Apple___Black_rot` \n",
    "- `Apple___Cedar_apple_rust` \n",
    "- `Apple___healthy` \n",
    "- `Blueberry___healthy` \n",
    "- `Cherry_(including_sour)___Powdery_mildew` \n",
    "- `Cherry_(including_sour)___healthy` \n",
    "- `Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot` \n",
    "- `Corn_(maize)___Common_rust_` \n",
    "- `Corn_(maize)___Northern_Leaf_Blight` \n",
    "- `Corn_(maize)___healthy', 'Grape___Black_rot` \n",
    "- `Grape___Leaf_blight_(Isariopsis_Leaf_Spot)` \n",
    "- `Grape___healthy` \n",
    "- `Orange___Haunglongbing_(Citrus_greening)` \n",
    "- `Peach___Bacterial_spot` \n",
    "- `Peach___healthy` \n",
    "- `Pepper,_bell___Bacterial_spot` \n",
    "- `Pepper,_bell___healthy` \n",
    "- `Potato___Early_blight` \n",
    "- `Potato___Late_blight` \n",
    "- `Potato___healthy` \n",
    "- `Raspberry___healthy` \n",
    "- `Soybean___healthy` \n",
    "- `Squash___Powdery_mildew` \n",
    "- `Strawberry___Leaf_scorch` \n",
    "- `Strawberry___healthy` \n",
    "- `Tomato___Bacterial_spot` \n",
    "- `Tomato___Late_blight` \n",
    "- `Tomato___Leaf_Mold` \n",
    "- `Tomato___Septoria_leaf_spot` \n",
    "- `Tomato___Spider_mites Two-spotted_spider_mite` \n",
    "- `Tomato___Target_Spot` \n",
    "- `Tomato___Tomato_Yellow_Leaf_Curl_Virus` \n",
    "- `Tomato___Tomato_mosaic_virus` \n",
    "- `Tomato___healthy`\n",
    "\n",
    "## References\n",
    "\n",
    "[1] Hughes, David P., and Marcel Salathe. “An Open Access Repository of Images on Plant Health to Enable the Development of Mobile Disease Diagnostics.” ArXiv:1511.08060 [Cs], Apr. 2016. arXiv.org, http://arxiv.org/abs/1511.08060.\n",
    "\n",
    "[2] Howard, Andrew G., et al. “MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications.” ArXiv:1704.04861 [Cs], Apr. 2017. arXiv.org, http://arxiv.org/abs/1704.04861.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mediterranean-chicken",
    "papermill": {
     "duration": 0.013228,
     "end_time": "2021-04-01T04:07:08.504993",
     "exception": false,
     "start_time": "2021-04-01T04:07:08.491765",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-01T04:07:08.536476Z",
     "iopub.status.busy": "2021-04-01T04:07:08.535876Z",
     "iopub.status.idle": "2021-04-01T04:07:13.362376Z",
     "shell.execute_reply": "2021-04-01T04:07:13.361254Z"
    },
    "id": "incredible-sarah",
    "papermill": {
     "duration": 4.844146,
     "end_time": "2021-04-01T04:07:13.362549",
     "exception": false,
     "start_time": "2021-04-01T04:07:08.518403",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-01T04:07:13.395984Z",
     "iopub.status.busy": "2021-04-01T04:07:13.394228Z",
     "iopub.status.idle": "2021-04-01T04:07:13.396556Z",
     "shell.execute_reply": "2021-04-01T04:07:13.396943Z"
    },
    "id": "comfortable-smart",
    "papermill": {
     "duration": 0.020743,
     "end_time": "2021-04-01T04:07:13.397075",
     "exception": false,
     "start_time": "2021-04-01T04:07:13.376332",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_size = 224\n",
    "target_size = (image_size, image_size)\n",
    "input_shape = (image_size, image_size, 3)\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "musical-approval",
    "papermill": {
     "duration": 0.014668,
     "end_time": "2021-04-01T04:07:13.425337",
     "exception": false,
     "start_time": "2021-04-01T04:07:13.410669",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Get data\n",
    "\n",
    "In order to make the most of our few training examples, we will \"augment\" them via a number of random transformations, so that our model would never see twice the exact same picture. This helps prevent overfitting and helps the model generalize better.\n",
    "\n",
    "In TensorFlow this can be done via the `tf.keras.preprocessing.image.ImageDataGenerator` class. This class allows you to:\n",
    "\n",
    "- configure random transformations and normalization operations to be done on your image data during training\n",
    "- instantiate generators of augmented image batches (and their labels) via `.flow(data, labels)` or `.flow_from_directory(directory)`. These generators can then be used with the `tf.keras` model methods that accept data generators as inputs, `fit`, `evaluate` and `predict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-01T04:07:13.458745Z",
     "iopub.status.busy": "2021-04-01T04:07:13.457024Z",
     "iopub.status.idle": "2021-04-01T04:07:13.459323Z",
     "shell.execute_reply": "2021-04-01T04:07:13.459723Z"
    },
    "id": "inclusive-mobility",
    "papermill": {
     "duration": 0.020892,
     "end_time": "2021-04-01T04:07:13.459844",
     "exception": false,
     "start_time": "2021-04-01T04:07:13.438952",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_dir = \"C:/Users/cosmo/Documents/Data science/Data Set/tywbtsjrjv-1/Plant leaf diseases dataset with augmentation/Plant leaf diseases dataset with augmentation\"\n",
    "train_dir = os.path.join(base_dir,\"train\")\n",
    "test_dir = os.path.join(base_dir,\"valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ready-branch",
    "papermill": {
     "duration": 0.013558,
     "end_time": "2021-04-01T04:07:13.487266",
     "exception": false,
     "start_time": "2021-04-01T04:07:13.473708",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We make the following augmentations to the images:\n",
    "\n",
    "- `width_shift` and `height_shift` are ranges (as a fraction of total width or height) within which to randomly translate pictures vertically or horizontally\n",
    "- `rescale` is a value by which we will multiply the data before any other processing. Our original images consist in RGB coefficients in the 0-255, but such values would be too high for our models to process (given a typical learning rate), so we target values between 0 and 1 instead by scaling with a 1/255. factor.\n",
    "- `shear_range` is for randomly applying shearing transformations\n",
    "- `zoom_range` is for randomly zooming inside pictures\n",
    "- `fill_mode` is the strategy used for filling in newly created pixels, which can appear after a rotation or a width/height shift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-01T04:07:13.521236Z",
     "iopub.status.busy": "2021-04-01T04:07:13.519528Z",
     "iopub.status.idle": "2021-04-01T04:07:13.521833Z",
     "shell.execute_reply": "2021-04-01T04:07:13.522229Z"
    },
    "id": "developmental-cable",
    "papermill": {
     "duration": 0.021313,
     "end_time": "2021-04-01T04:07:13.522351",
     "exception": false,
     "start_time": "2021-04-01T04:07:13.501038",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_datagen = keras.preprocessing.image.ImageDataGenerator(rescale = 1/255.0,\n",
    "                                                             shear_range = 0.2,\n",
    "                                                             zoom_range = 0.2,\n",
    "                                                             width_shift_range = 0.2,\n",
    "                                                             height_shift_range = 0.2,\n",
    "                                                             fill_mode=\"nearest\")\n",
    "\n",
    "test_datagen = keras.preprocessing.image.ImageDataGenerator(rescale = 1/255.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "normal-infection",
    "papermill": {
     "duration": 0.013653,
     "end_time": "2021-04-01T04:07:13.549901",
     "exception": false,
     "start_time": "2021-04-01T04:07:13.536248",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's prepare our data. We will use `.flow_from_directory()` to generate batches of image data (and their labels) directly from our images in their respective folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-01T04:07:13.582905Z",
     "iopub.status.busy": "2021-04-01T04:07:13.582223Z",
     "iopub.status.idle": "2021-04-01T04:07:29.847704Z",
     "shell.execute_reply": "2021-04-01T04:07:29.847231Z"
    },
    "id": "consecutive-lambda",
    "outputId": "afae601e-19b5-4b23-a4ba-31c2a0480fae",
    "papermill": {
     "duration": 16.284083,
     "end_time": "2021-04-01T04:07:29.847846",
     "exception": false,
     "start_time": "2021-04-01T04:07:13.563763",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'C:/Users/cosmo/Documents/Data science/Data Set/tywbtsjrjv-1/Plant leaf diseases dataset with augmentation/Plant leaf diseases dataset with augmentation\\\\train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-542d421078b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m                                                \u001b[0mtarget_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                                \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m                                                class_mode = \"categorical\")\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m test_data = test_datagen.flow_from_directory(test_dir,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[1;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001b[0m\n\u001b[0;32m    972\u001b[0m         \u001b[0mfollow_links\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfollow_links\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    973\u001b[0m         \u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 974\u001b[1;33m         interpolation=interpolation)\n\u001b[0m\u001b[0;32m    975\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    976\u001b[0m   def flow_from_dataframe(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[0;32m    390\u001b[0m         \u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m         \u001b[0minterpolation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 392\u001b[1;33m         **kwargs)\n\u001b[0m\u001b[0;32m    393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\directory_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'C:/Users/cosmo/Documents/Data science/Data Set/tywbtsjrjv-1/Plant leaf diseases dataset with augmentation/Plant leaf diseases dataset with augmentation\\\\train'"
     ]
    }
   ],
   "source": [
    "train_data = train_datagen.flow_from_directory(train_dir,\n",
    "                                               target_size = (image_size, image_size),\n",
    "                                               batch_size = batch_size,\n",
    "                                               class_mode = \"categorical\")\n",
    "\n",
    "test_data = test_datagen.flow_from_directory(test_dir,\n",
    "                                             target_size = (image_size, image_size),\n",
    "                                             batch_size = batch_size,\n",
    "                                             class_mode = \"categorical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "other-beach",
    "papermill": {
     "duration": 0.015093,
     "end_time": "2021-04-01T04:07:29.877769",
     "exception": false,
     "start_time": "2021-04-01T04:07:29.862676",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Create a classes index file\n",
    "\n",
    "We also want to know which class corresponds to which species and disease so we also create a `json` file which shows corresponding labels and class indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-01T04:07:29.911693Z",
     "iopub.status.busy": "2021-04-01T04:07:29.910987Z",
     "iopub.status.idle": "2021-04-01T04:07:29.914191Z",
     "shell.execute_reply": "2021-04-01T04:07:29.914622Z"
    },
    "id": "animated-growing",
    "outputId": "da8932c5-d787-4a61-b783-99be0d3b2a7b",
    "papermill": {
     "duration": 0.022425,
     "end_time": "2021-04-01T04:07:29.914749",
     "exception": false,
     "start_time": "2021-04-01T04:07:29.892324",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "categories = list(train_data.class_indices.keys())\n",
    "print(train_data.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-01T04:07:29.949797Z",
     "iopub.status.busy": "2021-04-01T04:07:29.949011Z",
     "iopub.status.idle": "2021-04-01T04:07:29.955775Z",
     "shell.execute_reply": "2021-04-01T04:07:29.956221Z"
    },
    "id": "educational-enough",
    "outputId": "2d98dbc0-76de-46aa-b286-58877c842537",
    "papermill": {
     "duration": 0.026623,
     "end_time": "2021-04-01T04:07:29.956345",
     "exception": false,
     "start_time": "2021-04-01T04:07:29.929722",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('class_indices.json','w') as f:\n",
    "  json.dump(train_data.class_indices, f)\n",
    "\n",
    "from IPython.display import FileLink\n",
    "FileLink(r'class_indices.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "broad-designer",
    "papermill": {
     "duration": 0.015625,
     "end_time": "2021-04-01T04:07:29.987400",
     "exception": false,
     "start_time": "2021-04-01T04:07:29.971775",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training\n",
    "\n",
    "We first get the base MobileNet model without including the top layers since we want to use it for 38 classes and us the pre-trained weights for ImageNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-01T04:07:30.025597Z",
     "iopub.status.busy": "2021-04-01T04:07:30.025088Z",
     "iopub.status.idle": "2021-04-01T04:07:34.002415Z",
     "shell.execute_reply": "2021-04-01T04:07:34.002880Z"
    },
    "id": "minimal-restriction",
    "outputId": "f1978c99-9e07-4098-d079-121db6898844",
    "papermill": {
     "duration": 4.000172,
     "end_time": "2021-04-01T04:07:34.003053",
     "exception": false,
     "start_time": "2021-04-01T04:07:30.002881",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.MobileNet(weights = \"imagenet\",\n",
    "                                             include_top = False,\n",
    "                                             input_shape = input_shape)\n",
    "\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "laughing-comment",
    "papermill": {
     "duration": 0.017473,
     "end_time": "2021-04-01T04:07:34.039284",
     "exception": false,
     "start_time": "2021-04-01T04:07:34.021811",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We now create a small upstream model on top of the MobileNet using the functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-01T04:07:34.082398Z",
     "iopub.status.busy": "2021-04-01T04:07:34.081337Z",
     "iopub.status.idle": "2021-04-01T04:07:34.261363Z",
     "shell.execute_reply": "2021-04-01T04:07:34.260757Z"
    },
    "id": "beginning-consent",
    "papermill": {
     "duration": 0.204784,
     "end_time": "2021-04-01T04:07:34.261506",
     "exception": false,
     "start_time": "2021-04-01T04:07:34.056722",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape = input_shape)\n",
    "\n",
    "x = base_model(inputs, training = False)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "x = tf.keras.layers.Dense(len(categories), \n",
    "                          activation=\"softmax\")(x)\n",
    "\n",
    "model = keras.Model(inputs = inputs, \n",
    "                    outputs = x, \n",
    "                    name=\"LeafDisease_MobileNet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "significant-occupation",
    "papermill": {
     "duration": 0.017852,
     "end_time": "2021-04-01T04:07:34.297136",
     "exception": false,
     "start_time": "2021-04-01T04:07:34.279284",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In our multiple experiments we found out Adam optimizer to work really well with it's default learning rate, $\\beta_1$, $\\beta_2$ and $\\epsilon$ values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-01T04:07:34.342978Z",
     "iopub.status.busy": "2021-04-01T04:07:34.342249Z",
     "iopub.status.idle": "2021-04-01T04:07:34.357035Z",
     "shell.execute_reply": "2021-04-01T04:07:34.356619Z"
    },
    "id": "suspended-thong",
    "papermill": {
     "duration": 0.042055,
     "end_time": "2021-04-01T04:07:34.357135",
     "exception": false,
     "start_time": "2021-04-01T04:07:34.315080",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "model.compile(optimizer = optimizer,\n",
    "              loss = tf.keras.losses.CategoricalCrossentropy(from_logits = True),\n",
    "              metrics=[keras.metrics.CategoricalAccuracy(), \n",
    "                       'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-01T04:07:34.396686Z",
     "iopub.status.busy": "2021-04-01T04:07:34.396128Z",
     "iopub.status.idle": "2021-04-01T04:39:03.182665Z",
     "shell.execute_reply": "2021-04-01T04:39:03.183196Z"
    },
    "id": "prostate-iceland",
    "outputId": "7c05838c-f2d2-4317-ee8c-b58c36f098ef",
    "papermill": {
     "duration": 1888.808672,
     "end_time": "2021-04-01T04:39:03.183361",
     "exception": false,
     "start_time": "2021-04-01T04:07:34.374689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_data,\n",
    "                    validation_data=test_data,\n",
    "                    epochs=epochs,\n",
    "                    steps_per_epoch=150,\n",
    "                    validation_steps=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "above-queue",
    "papermill": {
     "duration": 1.014709,
     "end_time": "2021-04-01T04:39:05.211508",
     "exception": false,
     "start_time": "2021-04-01T04:39:04.196799",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Review the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-01T04:39:07.585157Z",
     "iopub.status.busy": "2021-04-01T04:39:07.584228Z",
     "iopub.status.idle": "2021-04-01T04:39:07.733926Z",
     "shell.execute_reply": "2021-04-01T04:39:07.734336Z"
    },
    "id": "later-spectrum",
    "outputId": "e1b6b579-6a02-47b6-cdd1-675be08fac08",
    "papermill": {
     "duration": 1.17997,
     "end_time": "2021-04-01T04:39:07.734498",
     "exception": false,
     "start_time": "2021-04-01T04:39:06.554528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(loss))\n",
    "\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "plt.plot(epochs,loss,c=\"red\",label=\"Training\")\n",
    "plt.plot(epochs,val_loss,c=\"blue\",label=\"Validation\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-01T04:39:09.758242Z",
     "iopub.status.busy": "2021-04-01T04:39:09.745156Z",
     "iopub.status.idle": "2021-04-01T04:39:09.887262Z",
     "shell.execute_reply": "2021-04-01T04:39:09.887678Z"
    },
    "id": "dutch-wells",
    "outputId": "7e1f713f-36d3-4fe1-f6af-82cdca82b041",
    "papermill": {
     "duration": 1.156126,
     "end_time": "2021-04-01T04:39:09.887822",
     "exception": false,
     "start_time": "2021-04-01T04:39:08.731696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "acc = history.history['categorical_accuracy']\n",
    "val_acc = history.history['val_categorical_accuracy']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "plt.plot(epochs,acc,c=\"red\",label=\"Training\")\n",
    "plt.plot(epochs,val_acc,c=\"blue\",label=\"Validation\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "italian-slide",
    "papermill": {
     "duration": 0.999562,
     "end_time": "2021-04-01T04:39:11.880888",
     "exception": false,
     "start_time": "2021-04-01T04:39:10.881326",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Save the model\n",
    "\n",
    "We finally save the model in the standard TensorFlow 2 SavedModel format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-01T04:39:13.922335Z",
     "iopub.status.busy": "2021-04-01T04:39:13.921321Z",
     "iopub.status.idle": "2021-04-01T04:39:26.632303Z",
     "shell.execute_reply": "2021-04-01T04:39:26.629156Z"
    },
    "id": "perceived-license",
    "papermill": {
     "duration": 13.750988,
     "end_time": "2021-04-01T04:39:26.632446",
     "exception": false,
     "start_time": "2021-04-01T04:39:12.881458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save('plant_disease')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "plant-diseases-training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1948.674865,
   "end_time": "2021-04-01T04:39:30.668763",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-04-01T04:07:01.993898",
   "version": "2.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
